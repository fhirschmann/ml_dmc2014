This document gets compiled automatically with each svn commit and is available at:
[http://dmc.0x0b.de](http://dmc.0x0b.de).

```{r setup, echo=F}
library(knitr)
opts_chunk$set(echo=T, breaklines=T, fig.path="figure-notes/")
opts_knit$set(root.dir="../")
```
```{r echo=F, message=F, warning=F}
source("R/data.R")
source("R/utils.R")
source("R/dmc.R")
source("R/fs.R")
library(xtable)
library(ggplot2)
```
# DMC 2010

Goal is to predict whether a customer will return an item. Predictions
can be probabilities between 0 and 1.

# The Error Measure

The error measure is given by
```{r}
dmc.points <- function(pred, obs) {
    sum(abs(obs - pred))
}
```

There is probably much potential for tuning the probabilities, i.e.
when the classifier thinks the probability is 0.8, saying 0.8 will yield
an error of 0.2 according to the score used. So instead of using the plain
probabilities, we should probably round up/down at some point.

It should also be possible to use a classifier that does not output
probabilities like C5.0. The drawback is that if the prediction is incorrect,
the error measure rises by 1.

The following example illustrates this:
```{r}
obs <- c(1, 1, 0, 0, 1)
pred <- c(0.8, 0.9, 0.2, 0.2, 0.4)
d <- data.frame(pred=pred, obs=obs, error1=abs(pred - obs), error2=round(abs(pred - obs)))
d
sum(d$error1)
sum(d$error2)
```

# Points to consider

When making attributes such as `number of purchases per customer` or
`return rate for an item`, you're implicitly using information that
would otherwise not be available in the cross validation fold. So
we should be extremely careful with that.

As far as the return rate is concerned, we should check if the return
rate changes when calculating it with different hold-old folds.

# Data Analysis

## Before 

```{r}
str(dt.raw)
```

## After Preprocessing/Feature Engineering

```{r}
str(dt)
```

```{r}
summary(dt)
```

Observation: Women! Mostly! That's gotta be a clothing store.

## After general feature selection
```{r}
str(fs.all(dt))
```

## The size attribute

The size attribute is pretty broken:

```{r}
levels(dt.unclean$size)
```

Fix case:
```{r}
levels(as.factor(toupper(dt.unclean$size)))
```

We might be able to convert German clothing sizes to S/M/L/XL or vice verca.

## deliveryTime: Outlier

```{r}
hist(dt.unclean$deliveryTime)
```

```{r}
outliers <- !is.na(dt.unclean$deliveryTime) & dt.unclean$deliveryTime < 0
ht(dt.unclean[outliers, ][c("deliveryDate", "deliveryTime", "orderDate")], 20)
```

It's always 1990-12-31:

```{r}
unique(dt[outliers, ]$deliveryDate)
```

1990-12-31 is incorrect. 

Fix: 
Set them to NA (missing) for now and deal with it later.

```{r}
dt.unclean[outliers, ]$deliveryTime <- NA
dt.unclean[outliers, ]$deliveryDate <- NA
```

There might still be some outliers on the other end:
```{r}
hist(dt.unclean$deliveryTime)
```

But I don't think they are outliers. Some items may not be
on stock:

```{r}
tail(sort(dt$deliveryTime), 400)
```

## Does it make sense to include customerID as attribute?

Is customerID unique?

```{r}
length(unique(dt$customerID)) / length(dt$customerID)
```

Not at all.

How large is the intersection?

```{r}
length(intersect(dt$customerID, dt.test$customerID))
```

Out of how many instances:
```{r}
nrow(dt)
nrow(dt.test)
```

So it does make sense to use it in some sense.