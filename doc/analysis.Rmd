```{r setup, echo=F}
library(knitr)
opts_chunk$set(echo=T, breaklines=T, fig.width=10, fig.path="figure-analysis/")
opts_knit$set(root.dir="../")
#options(width=100)         
```

# DMC2014 Data Analysis

[This document](https://www.ke.informatik.tu-darmstadt.de/svn/DMC14/R/trunk/doc/analysis.Rmd)
is available at [http://dwxput6p.0x0b.de/analysis.html](http://dwxput6p.0x0b.de/analysis.html)
in its compiled form and is hooked onto the SVN. Please don't break the server.

## Helper functions/libraries needed for this Notebook
```{r echo=T, message=F, warning=F}
library(xtable)
library(ggplot2)
library(knitr)
library(data.table)
library(lubridate)
library(vcd)
library(psych)

plot.ddens <- function(v1, v2, ...) {
    plot(density(v1, na.rm=T), col="blue", ...)
    grid()
    lines(density(v2, na.rm=T), col="red")
    legend("topright", c("Train", "Test"), col = c("blue", "red"), lty = 1)
}

norm.lin <- function(x, mi=min(x), ma=max(x)) {
    (x - mi) / (ma - mi)
}

describe2 <- function(train, test) {
    rbind(psych::describe(train), psych::describe(test))[, 3:13]
}

returnRate <- function(subset) {
    sum(subset$returnRate) / nrow(subset)
}
```

## Read in the Data
```{r}
dt.train <- read.csv("task/orders_train.txt", sep=";", na.strings=c("?", "??", "NA", ""))
dt.test <- read.csv("task/orders_class.txt", sep=";", na.strings=c("?", "??", "NA", ""))

dt.dates <- c("dateOfBirth", "creationDate", "orderDate", "deliveryDate")
dt.train[dt.dates] <- lapply(dt.train[dt.dates], as.Date)
dt.test[dt.dates] <- lapply(dt.test[dt.dates], as.Date)

dt.merged <- rbind(data.frame(dt.train, group="train"),
                   data.frame(dt.test, group="test", returnShipment=NA))
```

## Score Function

The score function is given by

```{r}
score <- function(pred, obs) sum(abs(obs - pred))
```

### Baseline

Always say 1:

```{r}
score(1, dt.train$returnShipment)
```

Always say 0:

```{r}
score(0, dt.train$returnShipment)
```

## General data Analysis

### Attribute #, Types, Factor Levels, ...

```{r}
str(dt.train)
str(dt.test)
```

### Missing Values

```{r}
nas.train <- as.data.frame(apply(dt.train, 2, function(x) sum(is.na(x)) / length(x)))
nas.test <- as.data.frame(apply(dt.test, 2, function(x) sum(is.na(x)) / length(x)))
nas <- merge(nas.train, nas.test, by="row.names")
colnames(nas) <- c("Attribute", "Missing (Train)", "Missing (Test)")
kable(nas)
```

## Individual Attribute Analysis

### orderItemID

This item is unique and thus serves no purpose in the Machine Learning process:

```{r}
with(dt.train, length(unique(orderItemID)) / length(orderItemID))
with(dt.test, length(unique(orderItemID)) / length(orderItemID))
```

### orderDate

#### orderMonth
```{r}
qplot(month(orderDate, label=T), fill=group, data=dt.merged, position="dodge", binwidth=1)
```

```{r}
mosaic(returnShipment ~ month(orderDate), data=dt.train,
       main="Mosaic Plot of Month vs returnShipment")
```

#### orderWeekday

```{r}
mosaic(returnShipment ~ wday(orderDate, label=T, abbr=F), data=dt.train,
       main="Mosaic Plot of Weekday vs returnShipment")
```

#### orderMonth + orderWeekday

```{r}
mosaic(returnShipment ~ month(orderDate) + wday(orderDate, label=T, abbr=F),
       data=dt.train, main="Mosaic Plot of Weekday/Month vs returnShipment")
```

### deliveryDate

First, let's infer an attribute delivery time, which describes the time (in days)
the delivery has taken:

```{r}
dt.train$deliveryTime <- as.integer(dt.train$deliveryDate - dt.train$orderDate)
dt.test$deliveryTime <- as.integer(dt.test$deliveryDate - dt.test$orderDate)
```

And look for the obvious outliers:

```{r}
outl.train <- !is.na(dt.train$deliveryTime) & dt.train$deliveryTime < 0
outl.test <- !is.na(dt.test$deliveryTime) & dt.test$deliveryTime < 0

head(dt.train[outl.train, ])
```

Thesis: 1990-12-31 as deliveryDate for these outliers means that the delivery date
is not known.

```{r}
unique(dt.train[outl.train, ]$deliveryDate)
unique(dt.test[outl.test, ]$deliveryDate)
```

That's correct. So set them to NA:

```{r}
dt.train[outl.train, ]$deliveryDate <- NA
dt.train[outl.train, ]$deliveryTime <- NA
dt.test[outl.test, ]$deliveryDate <- NA
dt.test[outl.test, ]$deliveryTime <- NA
```

Plot it:

```{r}
par(mfrow=c(1, 2))

hist(dt.train$deliveryTime, main="Histogram of deliveryTime (Train)", xlab="Time (days)")
hist(dt.test$deliveryTime, main="Histogram of deliveryTime (Test)", xlab="Time (days)")
```

Do some descriptive statistics:

```{r}
kable(describe2(dt.train$deliveryTime, dt.test$deliveryTime))
```

A kernel density estimate is probably better:

```{r}
plot.ddens(dt.train$deliveryTime, dt.test$deliveryTime,
           main="Kernel Density Estimate of Delivery Time", xlab="Time (days)")
plot.ddens(dt.train$deliveryTime, dt.test$deliveryTime, xlim=c(0, 40),
           main="Kernel Density Estimate of Delivery Time", xlab="Time (days)")
```

Both are positively skewed and thus have a long tail on the right. The kurtosis is
much higher for the train set, hence the higher peak.

### itemID

### size

### color

```{r}
col.train <- data.frame(table(dt.train$color))
colnames(col.train) <- c("color", "Train")
col.train$Train <- round(col.train$Train / nrow(dt.train), 8)

col.test <- data.frame(table(dt.test$color))
colnames(col.test) <- c("color", "Test")
col.test$Test <- round(col.test$Test / nrow(dt.test), 8)

m <- merge(col.train, col.test, by=1, all.x=T, all.y=T)
m$Ratio <- m$Train / m$Test
m[order(m$Ratio, decreasing=T), ]
```

### manufacturerID

### price

```{r}
mosaic(returnShipment ~ cut(price, c(0, 20, 39, 40, 50, 60, 1000)),
       data=dt.train, main="Mosaic Plot of Price vs returnShipment")
```

```{r, cache=T}
steps <- c(1:100 * 2, 300)
ret <- t(sapply(steps, function(x) table(dt.train[with(dt.train, price < x), ]$returnShipment)))
head(ret)
plot(steps, ret[, 2] / (ret[, 1] + ret[, 2]), type="l",
     xlab="Maximum Price (EUR) in 2 EUR steps", ylab="Ratio of returnShipment",
     main="Maximum Price vs returnShipment")
```

Let's compare train vs test set using descriptive statistics (first row
corresponds to the train set):

```{r}
kable(describe2(dt.train$price, dt.test$price))
```

```{r}
plot.ddens(dt.train$price, dt.test$price, main="Kernel Density Estimate of Price",
           xlab="price (EUR)")
```

Both are positively skewed and thus have a long tail on the right. The kurtosis is
higher for the train set, hence the higher peak.

Zoom in:

```{r}
plot.ddens(dt.train$price, dt.test$price, main="Kernel Density Estimate of Price",
           xlab="price (EUR)", xlim=c(0, 300))
```

Particularly interesting is the fact that the density is highest around prices
of 9.99, 19.99 and lowest around prices of 10, 20. This might give you an appropriate
clue as to what breakpoints to use when discretizing the price.

For example:
```{r}
par(mfrow=c(1, 2), mar=c(5.1, 5.1, 4.1, 2.1))

barplot(table(with(dt.train, cut(price, c(0, 1:20 * 10, Inf), left=T, right=F))), las=1,
        main="Histogram of Discretized Prices (Train)", horiz=T)
barplot(table(with(dt.test, cut(price, c(0, 1:20 * 10, Inf), left=T, right=F))), las=1,
        main="Histogram of Discretized Prices (Test)", horiz=T)
```

### customerID

#### Is the same customerID used for more than one person?

```{r}
dt <- data.table(dt.merged)

nrow(dt[, c("customerID"), by=list(customerID, salutation, dateOfBirth)])
length(unique(dt$customerID))
```

No.

#### Is customerID unique?

```{r}
length(unique(dt.train$customerID)) / length(dt.train$customerID)
```

Not at all.

#### How large is the intersection between the train and test set?

```{r}
length(intersect(dt.train$customerID, dt.test$customerID))
```

Out of how many instances:
```{r}
nrow(dt.train)
nrow(dt.test)
```

So it does make sense to use it in some form.

#### Is there a customer ID that appears unusually often?

```{r}
tail(sort(table(dt.train$customerID)), 10)
tail(sort(table(dt.test$customerID)), 10)
```

No.

### salutation

It's a women store:
```{r}
p <- t(rbind(prop.table(table(dt.train$salutation)),
             prop.table(table(dt.test$salutation))))
colnames(p) <- c("Contingency (Train)", "Contingency (Test)")
kable(p)
```

There are even more women (relatively) in the test set.

### dateOfBirth

We'll take a look at the histograms first:
```{r}
par(mfrow=c(1, 2))
barplot(table(dt.train$dateOfBirth), main="Histogram of dateOfBirth (Train)")
barplot(table(dt.test$dateOfBirth), main="Histogram of dateOfBirth (Test)")
```

Two points become obvious:
- Nobody lives that long.
- There is at least one DOB that appears unusually often in the two sets.

Which DOB appears that often?

```{r}
tail(sort(table(dt.train$dateOfBirth)))
tail(sort(table(dt.test$dateOfBirth)))
```

Set the dateOfBirth Attribute of these outliers to NA:

```{r}
outl.train <- with(dt.train, !is.na(dateOfBirth) & dateOfBirth %in% c(as.Date("1900-11-19"), as.Date("1949-11-19")))
outl.test <- with(dt.test, !is.na(dateOfBirth) & dateOfBirth %in% c(as.Date("1900-11-19"), as.Date("1949-11-19")))

dt.train[outl.train, ]$dateOfBirth <- NA
dt.test[outl.test, ]$dateOfBirth <- NA
```

Let's take a look again:

```{r}
par(mfrow=c(1, 2))
barplot(table(dt.train$dateOfBirth), main="Histogram of dateOfBirth (Train)")
barplot(table(dt.test$dateOfBirth), main="Histogram of dateOfBirth (Test)")
```

Looks alright.

But... what about the superhumans?

```{r}
head(sort(dt.test$dateOfBirth))
head(sort(dt.train$dateOfBirth))
```

Only three in the train set, so let's set them to NA as well:

```{r}
outl.train <- with(dt.train, !is.na(dateOfBirth) & dateOfBirth == as.Date("1655-04-19"))

dt.train[outl.train, ]$dateOfBirth <- NA
```

Let's compute an age attribute:

```{r}
dt.train$customerAge <- as.integer(2013 - year(dt.train$dateOfBirth))
dt.test$customerAge <- as.integer(2013 - year(dt.test$dateOfBirth))
```

And plot it:
```{r}
par(mfrow=c(1, 2))

hist(dt.train$customerAge, main="Customer Age (Train)")
hist(dt.test$customerAge, main="Customer Age (Test)")
```

There are still some outliers on both ends, so we set them to NA as well:

```{r}
outl.train <- with(dt.train, !is.na(customerAge) & (customerAge > 85 | customerAge < 19))
outl.test <- with(dt.test, !is.na(customerAge) & (customerAge > 85 | customerAge < 19))

dt.train[outl.train, ]$dateOfBirth <- NA
dt.train[outl.train, ]$customerAge <- NA

dt.test[outl.test, ]$dateOfBirth <- NA
dt.test[outl.test, ]$customerAge <- NA
```

Let's do some descriptive statistics:

```{r}
kable(describe2(dt.train$customerAge, dt.test$customerAge))
```

Then we do a Quantile-Quantile plot against the normal distribution:
```{r}
par(mfrow=c(1, 2))

qqnorm(dt.train$customerAge, main="Customer Age Normal Q-Q Plot (Train)")
grid()
qqline(dt.train$customerAge, col="red")
qqnorm(dt.test$customerAge, main="Customer Age Normal Q-Q Plot (Test)")
grid()
qqline(dt.train$customerAge, col="red")
```

You can clearly see that the age is normally distributed. However, 
due to the slightly positive skew and kurtosis, you can see that the distribution
deviates from the normal distribution in its tails.

#### Customer Age vs returnShipment

First, let's create a high-dimensional contingency table:

```{r}
x <- structable(returnShipment ~ customerAge, data=dt.train)
x[1:10, ]  # first 10 elements

r <- x[, 2] / (x[, 1] + x[, 2])  # ratio of returned items for each age
plot(rownames(r), r, type="l", main="Ratio of Returned Items vs Age",
     xlab="Age", ylab="Returned Items (Ratio)", col="blue")
grid()
lines(supsmu(as.numeric(rownames(r)), r), col="red")
legend("topright", c("Return Ratio", "Return Ratio (Smoothed (Friedman 1984))"),
       col = c("blue", "red"), lty = 1)
```

### state

```{r}
load(url("http://gadm.org/data/rda/DEU_adm1.RData"))
```

### creationDate

```{r}
tail(sort(table(dt.train$creationDate)))
tail(sort(table(dt.test$creationDate)))
```

The last date appears unusually often. Remove it:

```{r}
outl.train <- with(dt.train, creationDate == as.Date("2011-02-16"))
outl.test <- with(dt.test, creationDate == as.Date("2011-02-16"))

dt.train[outl.train, ]$creationDate <- NA
dt.test[outl.test, ]$creationDate <- NA
```

```{r}
accsum <- cumsum(table(data.table(dt.merged)[,c("creationDate"),
                                            by=list(customerID, creationDate)
                                            ]$creationDate))
plot(as.Date(names(accsum)), accsum, type="l", main="Number of Registered Accounts",
     xlab="Date", ylab="# of Accounts", xaxt="n")
axis(1, as.Date(names(accsum)), format(as.Date(names(accsum)), "%b %y"))
grid()
```

### returnShipment

## holiday skew

Train data date range:

```{r}
min(dt.train$orderDate)
max(dt.train$orderDate)
```

Test data date range:

```{r}
min(dt.test$orderDate)
max(dt.test$orderDate)
```

Easter Sunday 2012: 2012-04-08
Easter Sunday 2013: 2012-03-31

This means, the train data includes the week before Easter Sunday for both 2012 and 2013 while the test data represents the 30 days after Easter Sunday.

```{r}
train.after.easter <- subset(dt.train, orderDate >= ymd('2012-04-09') & orderDate < (ymd('2012-04-09') + days(30)))

nrow(train.after.easter)
nrow(dt.test)

nrow(train.after.easter) / nrow(dt.test)

returnRate(train.after.easter)
```

The train data set for the relevant period of the previous year is 71.99%.
The return rate is 48.50% for the after easter period.

TODO

- include school holidays (easter & pentecost), filter by federal state
- compare to pentecost holidays
- compare to "innocent" timeperiod
    - what's a good candidate?
- check christmas skew
- check distributions of train.after.easter vs dt.test

## Cleaned Data

```{r}
dt.train$customerAge <- NULL
dt.train$deliveryTime <- NULL
write.table(dt.train, file="task/orders_train.clean.txt", sep=";", na="?",
            quote=F, row.names=F)
dt.test$customerAge <- NULL
dt.test$deliveryTime <- NULL
write.table(dt.test, file="task/orders_class.clean.txt", sep=";", na="?",
            quote=F, row.names=F)
```

The cleaned data is [available](http://dwxput6p.0x0b.de/).
Do note that *no* instances have been removed. The
outliers simply had their outlying attribute set to NA/?.

## SessionInfo

```{r}
sessionInfo()
```
