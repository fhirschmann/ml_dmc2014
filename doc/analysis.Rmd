```{r setup, echo=F}
library(knitr)
opts_chunk$set(echo=T, breaklines=T, fig.width=10, fig.path="figure-analysis/")
opts_knit$set(root.dir="../")
#options(width=100)         
```

# DMC2014 Data Analysis

[This document](https://www.ke.informatik.tu-darmstadt.de/svn/DMC14/R/trunk/doc/analysis.Rmd)
is available at [http://dwxput6p.0x0b.de/analysis.html](http://dwxput6p.0x0b.de/analysis.html)
in its compiled form and is hooked onto the SVN. Please don't break the server.

## Helper functions/libraries needed for this Notebook
```{r echo=T, message=F, warning=F}
library(xtable)
library(ggplot2)
library(knitr)
library(data.table)
library(lubridate)
library(vcd)
library(psych)
library(plyr)

plot.ddens <- function(v1, v2, v3=NULL, ...) {
    d1 <- density(v1, na.rm=T)
    plot(d1, col="blue", ...)
    grid()
    lines(density(v2, na.rm=T, bw=d1$bw), col="red")
    if (is.null(v3)) {
        legend("topright", c("Train", "Test"), col = c("blue", "red"), lty = 1)
    } else {
        legend("topright", c("Train", "Test", "Train (Sample)"), col = c("blue", "red", "green"), lty = 1)
        lines(density(v3, na.rm=T, bw=d1$bw), col="green")
    }
}

norm.lin <- function(x, mi=min(x), ma=max(x)) {
    (x - mi) / (ma - mi)
}

describe2 <- function(train, test) {
    rbind(psych::describe(train), psych::describe(test))[, 3:13]
}

returnRate <- function(subset) {
    sum(subset$returnShipment) / nrow(subset)
}
```

## Read in the Data
```{r}
dt.train <- read.csv("task/orders_train.txt", sep=";", na.strings=c("?", "??", "NA", ""))
dt.test <- read.csv("task/orders_class.txt", sep=";", na.strings=c("?", "??", "NA", ""))

dt.dates <- c("dateOfBirth", "creationDate", "orderDate", "deliveryDate")
dt.train[dt.dates] <- lapply(dt.train[dt.dates], as.Date)
dt.test[dt.dates] <- lapply(dt.test[dt.dates], as.Date)

dt.merged <- rbind(data.frame(dt.train, group="train"),
                   data.frame(dt.test, group="test", returnShipment=NA))
```

## Score Function

The score function is given by

```{r}
score <- function(pred, obs) sum(abs(obs - pred))
```

### Baseline

Always say 1:

```{r}
score(1, dt.train$returnShipment)
```

Always say 0:

```{r}
score(0, dt.train$returnShipment)
```

## General data Analysis

### Attribute #, Types, Factor Levels, ...

```{r}
str(dt.train)
str(dt.test)
```

### Missing Values

```{r}
nas.train <- as.data.frame(apply(dt.train, 2, function(x) sum(is.na(x)) / length(x)))
nas.test <- as.data.frame(apply(dt.test, 2, function(x) sum(is.na(x)) / length(x)))
nas <- merge(nas.train, nas.test, by="row.names")
colnames(nas) <- c("Attribute", "Missing (Train)", "Missing (Test)")
kable(nas)
```

## Individual Attribute Analysis

### orderItemID

This item is unique and thus serves no purpose in the Machine Learning process:

```{r}
with(dt.train, length(unique(orderItemID)) / length(orderItemID))
with(dt.test, length(unique(orderItemID)) / length(orderItemID))
```

### orderDate

#### orderMonth
```{r}
qplot(month(orderDate, label=T), fill=group, data=dt.merged, position="dodge", binwidth=1)
```

```{r}
mosaic(returnShipment ~ month(orderDate), data=dt.train,
       main="Mosaic Plot of Month vs returnShipment")
```

#### orderWeekday

```{r}
mosaic(returnShipment ~ wday(orderDate, label=T, abbr=F), data=dt.train,
       main="Mosaic Plot of Weekday vs returnShipment")
```

#### orderMonth + orderWeekday

```{r}
mosaic(returnShipment ~ month(orderDate) + wday(orderDate, label=T, abbr=F),
       data=dt.train, main="Mosaic Plot of Weekday/Month vs returnShipment")
```

### deliveryDate

#### Missing Delivery Dates

```{r}
dt <- dt.train
dt$deliveryDateMissing <- ifelse(is.na(dt$deliveryDate), "yes", "no")
structable(returnShipment ~ deliveryDateMissing, data=dt)
```

Cool! :)

How many delivery dates are missing in the test set?

```{r}
count(is.na(dt.test$deliveryDate))
```

Awesome.

Make this an attribute:
```{r}
dt.train$deliveryDateMissing <- as.factor(ifelse(is.na(dt.train$deliveryDate), "yes", "no"))
dt.test$deliveryDateMissing <- as.factor(ifelse(is.na(dt.test$deliveryDate), "yes", "no"))
```

#### Outliers

First, let's infer an attribute delivery time, which describes the time (in days)
the delivery has taken:

```{r}
dt.train$deliveryTime <- as.integer(dt.train$deliveryDate - dt.train$orderDate)
dt.test$deliveryTime <- as.integer(dt.test$deliveryDate - dt.test$orderDate)
```

And look for the obvious outliers:

```{r}
outl.train <- !is.na(dt.train$deliveryTime) & dt.train$deliveryTime < 0
outl.test <- !is.na(dt.test$deliveryTime) & dt.test$deliveryTime < 0

head(dt.train[outl.train, ])
```

Thesis: 1990-12-31 as deliveryDate for these outliers means that the delivery date
is not known.

```{r}
unique(dt.train[outl.train, ]$deliveryDate)
unique(dt.test[outl.test, ]$deliveryDate)
```

That's correct. So set them to NA:

```{r}
dt.train[outl.train, ]$deliveryDate <- NA
dt.train[outl.train, ]$deliveryTime <- NA
dt.test[outl.test, ]$deliveryDate <- NA
dt.test[outl.test, ]$deliveryTime <- NA
```

Plot it:

```{r}
par(mfrow=c(1, 2))

hist(dt.train$deliveryTime, main="Histogram of deliveryTime (Train)", xlab="Time (days)")
hist(dt.test$deliveryTime, main="Histogram of deliveryTime (Test)", xlab="Time (days)")
```

Do some descriptive statistics:

```{r}
kable(describe2(dt.train$deliveryTime, dt.test$deliveryTime))
```

A kernel density estimate is probably better:

```{r}
plot.ddens(dt.train$deliveryTime, dt.test$deliveryTime,
           main="Kernel Density Estimate of Delivery Time", xlab="Time (days)")
plot.ddens(dt.train$deliveryTime, dt.test$deliveryTime, xlim=c(0, 40),
           main="Kernel Density Estimate of Delivery Time", xlab="Time (days)")
```

Both are positively skewed and thus have a long tail on the right. The kurtosis is
much higher for the train set, hence the higher peak.

### itemID

#### Group SMETT's findings

```{r, fig.height=8}
par(xpd=F, mar=c(8.1, 5.1, 5.1, 2.1), mgp=c(6, 1, 0))
smoothScatter(dt.merged$orderDate, dt.merged$itemID, main="orderDate vs itemID", xlab="Month", ylab="itemID",
              xaxt="n")
abline(v=max(dt.train$orderDate), col="red")
par(xpd=T)
legend("topleft", c("Test Set Start"), lty=c(1), col=c("red"))
lbls <- as.Date(c("2012-04-01", "2012-05-01", "2012-06-01", "2012-07-01", "2012-08-01", "2012-09-01",
                  "2012-10-01", "2012-11-01", "2012-12-01", "2013-01-01", "2013-02-01", "2013-03-01",
                  "2013-04-01", "2013-04-30"))
axis(1, lbls, lbls, las=2)
```

```{r, fig.height=8}
par(xpd=F, mar=c(8.1, 5.1, 5.1, 2.1), mgp=c(6, 1, 0))
smoothScatter(as.integer(dt.merged$orderItemID), dt.merged$itemID, main="orderItemID vs itemID", xlab="Month",
              ylab="itemID", xaxt="n")
abline(v=max(as.integer(dt.train$orderItemID)), col="red")
legend("topleft", c("Test Set Start"), lty=c(1), col=c("red"))
lbls <- seq(0, 480000, 20000)
axis(1, lbls, lbls, las=2)
```

#### How large is the intersection between the train and test set?

```{r}
length(intersect(dt.train$itemID, dt.test$itemID))
```

Out of how many customers?
```{r}
length(unique(dt.train$itemID))
length(unique(dt.test$itemID))
```

Observation: Almost all items in the test set are present in the train set.

How many instances (in %) are in the intersect?

```{r}
i <- intersect(dt.train$itemID, dt.test$itemID)
nrow(dt.train[dt.train$itemID %in% i,]) / nrow(dt.train) * 100
```

How about the train set?

```{r}
nrow(dt.test[dt.test$itemID %in% i,]) / nrow(dt.test) * 100
```

#### Are there items that are always returned?

```{r}
x <- as.data.frame.matrix(structable(returnShipment ~ itemID, data=dt.train))
head(x[x[["0"]] == 0, ])
```

Yes, but for items which have only been ordered a few times this is not
really significant. Let's see about the items which have been ordered
more than 5 times:

```{r}
x[x[["0"]] == 0 & x[["1"]] > 5,]
```

Only three items that have been ordered a total of 29 times.

How about the intersection of the train and testset over the months?

```{r}
dt.merged$month <- ((year(dt.merged$orderDate)-2012)*12 + month(dt.merged$orderDate)) - 3
tbl2monthPercent <- t(sapply(1:12, function(w) length(intersect(unique(dt.test$itemID), unique(dt.merged[dt.merged$month == w, ]$itemID))) / length(unique(dt.test$itemID))))
tbl2monthPercent
```

Bad: The first three months which seem like a similar time for purchases clothing-style-wise (spring/summer collection) only have a 14-15 percent intersection with the testset. Good: The last three months have a high intersection with over 90 percent. You can also really see the change from winter to summer collection, within one month (from december to january), the intersection jumps from 44 to 92 percent.

### size

### color

```{r}
col.train <- data.frame(table(dt.train$color))
colnames(col.train) <- c("color", "Train")
col.train$Train <- round(col.train$Train / nrow(dt.train), 8)

col.test <- data.frame(table(dt.test$color))
colnames(col.test) <- c("color", "Test")
col.test$Test <- round(col.test$Test / nrow(dt.test), 8)

m <- merge(col.train, col.test, by=1, all.x=T, all.y=T)
m$Ratio <- m$Train / m$Test
print(m[order(m$Ratio, decreasing=T), ], digits=8)
```

Too many colors, many almost the same ... mapping:
```{r, message=F}
colors <- function(x) {revalue(x, c("dark denim"="black", #blue?
                      "dark navy"="blue",
                      "ash"="grey",
                      "bordeaux"="red",
                      "mahagoni"="red", #brown?
                      "gold"="yellow",
                      "dark oliv"="green",
                      "striped"="other",
                      "anthracite"="black", #grey?
                      "antique pink"="red",
                      "floral"="other", #?
                      "baltic blue"="blue",
                      "nature"="other", #?
                      "ancient"="other", #?
                      "curry"="yellow",
                      "turquoise"="blue",
                      "navy"="blue",
                      "brown"="brown",
                      "aubergine"="red", #brown?
                      "mocca"="brown", #grey?
                      "blau"="blue",
                      "basalt"="grey",
                      "azure"="blue",
                      "coral"="red", #yellow?
                      "pallid"="grey", #?
                      "petrol"="blue",
                      "silver"="grey",
                      "habana"="red", #?
                      "darkblue"="blue",
                      "beige"="yellow", #brown/grey?
                      "mint"="green",
                      "khaki"="brown", #yellow?
                      "hibiscus"="red",
                      "orange"="red", #yellow?
                      "yellow"="yellow",
                      "black"="black",
                      "blue"="blue",
                      "purple"="red",
                      "almond"="brown", #yellow?
                      "red"="red",
                      "berry"="red",
                      "grey"="grey",
                      "ocher"="brown",
    				  "avocado"="green",
                      "magenta"="red",
                      "olive"="green",
                      "white"="white",
                      "denim"="other", #?
                      "pink"="red",
                      "stained"="brown",
                      "kanel"="brown", #red?
                      "green"="green",
                      "jade"="green",
                      "aquamarine"="blue",
                      "aqua"="blue",
                      "ecru"="grey", #brown/yellow?
                      "iron"="grey",
                      "fuchsia"="red",
                      "ingwer"="red", #brown?
                      "cognac"="brown",
                      "terracotta"="brown", #red?
                      "apricot"="yellow",
                      "graphite"="grey",
                      "crimson"="red",
                      "lemon"="yellow",
                      "oliv"="green",
                      "leopard"="yellow", #brown/other?
                      "amethyst"="red",
                      "aviator"="other", #?
                      "bronze"="brown",
                      "brwon"="brown",
                      "caramel"="yellow",
                      "champagner"="yellow", #grey?
                      "cobalt blue"="blue",
                      "copper coin"="brown",
                      "cortina mocca"="brown",
                      "creme"="yellow",
                      "curled"="other", #?
                      "currant purple"="red",
                      "dark garnet"="black", #red?
                      "dark grey"="grey",
                      "ebony"="black",
                      "ivory"="white",
                      "mango"="yellow",
                      "opal"="other", #kann alles sein
                      "perlmutt"="other", #?
                      "vanille"="white"))}
dt.train$fewcolors <- colors(dt.train$color)
dt.test$fewcolors <- colors(dt.test$color)
dt.merged$fewcolors <- colors(dt.merged$color)
```
                      
as you can see, not really clear to say for each color.
plotted:

```{r, warning=F, message=F}
p <- rbind(data.frame(prop.table(table(dt.test$fewcolors)), group="test"),
           data.frame(prop.table(table(dt.train$fewcolors)), group="train"))

ggplot(p, aes(x=Var1, y=Freq, fill=group)) + geom_bar(position="dodge") + 
    ggtitle("Color Frequencies in the Train and Test Set") +
    xlab("Color") + ylab("Frequency")
```

Roughly the same distribution, but green shows the greatest difference.

Lets have a look at the colors over the months:

```{r, warning=F, message=F}
dt.merged$month <- ((year(dt.merged$orderDate)-2012)*12 + month(dt.merged$orderDate)) - 3
tbl <- t(sapply(1:13, function(w) prop.table(table(dt.merged[dt.merged$month == w, ]$fewcolors))))

rownames(tbl) <- 1:13


plot(rownames(tbl),tbl[,"brown"], type="l", xlab="months", ylab="popularity of color in percent (of all colors)", col="brown", ylim=c(0,0.4), xaxt="n")
axis(1, at=1:13, labels=c("Apr", "Mar", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec", "Jan", "Feb", "Mar", "Apr"))

lines(rownames(tbl), tbl[, "red"], col="red")
lines(rownames(tbl), tbl[, "other"], col="pink")   #other
lines(rownames(tbl), tbl[, "black"], col="black")
lines(rownames(tbl), tbl[, "yellow"], col="yellow")
lines(rownames(tbl), tbl[, "blue"], col="blue")   
lines(rownames(tbl), tbl[, "grey"], col="grey")
lines(rownames(tbl), tbl[, "green"], col="green")
lines(rownames(tbl), tbl[, "white"], col="orange") #white
```

colors are selfexplanatory except for: pink = other, orange = white

months = the months, starting 1 = april, ending 13 = april (testset)

We see: blue, red, brown dont change much. Black rises, white/grey falls at the end of the summer and in cold months. Yellow and 'other' stay very low the whole time. Green rises all the time, which explains the difference in the other barplot.

Additionally: Looked up spring/summer trends 2012/2013.

- 2012: knallig / sandfarben / sommerfarbe himmelblau / strahlendes weiß
- 2013: grafische muster / glänzend / transparent / asiastyle

Generell schwer zu sagen, da jede modeseite da andere Meinungen hat.

### manufacturerID

#### Is the same itemID used with two differing manufacturers?

```{r}
nrow(unique(dt.train[c("manufacturerID", "itemID")]))
length(unique(dt.train$itemID))

nrow(unique(dt.test[c("manufacturerID", "itemID")]))
length(unique(dt.test$itemID))

```

- train: 4 itemIDs have more than one manufacturer
- test: itemID is unique

what about manufacturerID in train and test?

```{r}
length(unique(dt.train$manufacturerID))
length(setdiff(dt.train$manufacturerID, dt.test$manufacturerID))
length(setdiff(dt.test$manufacturerID, dt.train$manufacturerID))
```
- 165 manufacturer, 119 of them also in the test set
- 46 manufacturers do appear in the train but not the test set

### price

```{r}
mosaic(returnShipment ~ cut(price, c(0, 20, 39, 40, 50, 60, 1000)),
       data=dt.train, main="Mosaic Plot of Price vs returnShipment")
```

```{r, cache=T}
steps <- c(1:100 * 2, 300)
ret <- t(sapply(steps, function(x) table(dt.train[with(dt.train, price < x), ]$returnShipment)))
head(ret)
plot(steps, ret[, 2] / (ret[, 1] + ret[, 2]), type="l",
     xlab="Maximum Price (EUR) in 2 EUR steps", ylab="Ratio of returnShipment",
     main="Maximum Price vs returnShipment")
```

Let's compare train vs test set using descriptive statistics (first row
corresponds to the train set):

```{r}
kable(describe2(dt.train$price, dt.test$price))
```

```{r}
plot.ddens(dt.train$price, dt.test$price, main="Kernel Density Estimate of Price",
           xlab="price (EUR)", ylim=c(0, 0.018))
```

Both are positively skewed and thus have a long tail on the right. The kurtosis is
higher for the train set, hence the higher peak.

Zoom in:

```{r}
plot.ddens(dt.train$price, dt.test$price, main="Kernel Density Estimate of Price",
           xlab="price (EUR)", xlim=c(0, 300), ylim=c(0, 0.020))
```

Particularly interesting is the fact that the density is highest around prices
of 9.99, 19.99 and lowest around prices of 10, 20. This might give you an appropriate
clue as to what breakpoints to use when discretizing the price.

For example:
```{r}
par(mfrow=c(1, 2), mar=c(5.1, 5.1, 4.1, 2.1))

barplot(table(with(dt.train, cut(price, c(0, 1:20 * 10, Inf), left=T, right=F))), las=1,
        main="Histogram of Discretized Prices (Train)", xlab="# of instances", horiz=T)
barplot(table(with(dt.test, cut(price, c(0, 1:20 * 10, Inf), left=T, right=F))), las=1,
        main="Histogram of Discretized Prices (Test)", xlab="# of instances", horiz=T)
```

### customerID

#### Is the same customerID used for more than one person?

```{r}
dt <- data.table(dt.merged)

nrow(dt[, c("customerID"), by=list(customerID, salutation, dateOfBirth)])
length(unique(dt$customerID))
```

No.

#### Is customerID unique?

```{r}
length(unique(dt.train$customerID)) / length(dt.train$customerID)
```

Not at all.

#### How large is the intersection between the train and test set?

```{r}
length(intersect(dt.train$customerID, dt.test$customerID))
```

Out of how many customers?
```{r}
length(unique(dt.train$customerID))
length(unique(dt.test$customerID))
```

So it does make sense to use it in some form.

How many instances (in %) are in the intersect?

```{r}
i <- intersect(dt.train$customerID, dt.test$customerID)
nrow(dt.train[dt.train$customerID %in% i,]) / nrow(dt.train) * 100
```

How about the train set?

```{r}
nrow(dt.test[dt.test$customerID %in% i,]) / nrow(dt.test) * 100
```

#### Is there a customer ID that appears unusually often?

```{r}
tail(sort(table(dt.train$customerID)), 10)
tail(sort(table(dt.test$customerID)), 10)
```

No.

#### Are there customers that always return items?

```{r}
x <- as.data.frame.matrix(structable(returnShipment ~ customerID, data=dt.train))
head(x[x[["0"]] == 0, ])
```

Yes, but for cases where these customers have only ordered a few times this is not
really significant. Let's see about the customers which have ordered
more than 9 items:

```{r}
nrow(x[x[["0"]] == 0 & x[["1"]] > 9,])
```

There are 146 of these customers.

Another import aspect might be how many orders these customers have placed:

```{r}
z <- dt.train[dt.train$customerID %in% rownames(x[x[["0"]] == 0, ]), c("customerID", "orderDate")]
z <- z[!duplicated(z), ]
zz <- as.data.frame(table(z$customerID))
table(zz$Freq)
```

The 6225 customers who have placed only 1 order and returned all of the items
are negligible. 

If we set the cutoff at 2, i.e. customers who have placed more than 2 orders,
how many test set instances does this relate to?

```{r}
nrow(dt.test[dt.test$customerID %in% zz[zz$Freq > 2,]$Var1, ])
```
### salutation

It's a women store:
```{r}
p <- t(rbind(prop.table(table(dt.train$salutation)),
             prop.table(table(dt.test$salutation))))
colnames(p) <- c("Contingency (Train)", "Contingency (Test)")
kable(p)
```

There are even more women (relatively) in the test set.

### dateOfBirth

We'll take a look at the histograms first:
```{r}
par(mfrow=c(1, 2))
barplot(table(dt.train$dateOfBirth), main="Histogram of dateOfBirth (Train)")
barplot(table(dt.test$dateOfBirth), main="Histogram of dateOfBirth (Test)")
```

Two points become obvious:
- Nobody lives that long.
- There is at least one DOB that appears unusually often in the two sets.

Which DOB appears that often?

```{r}
tail(sort(table(dt.train$dateOfBirth)))
tail(sort(table(dt.test$dateOfBirth)))
```

Set the dateOfBirth Attribute of these outliers to NA:

```{r}
outl.train <- with(dt.train, !is.na(dateOfBirth) & dateOfBirth %in% c(as.Date("1900-11-19"), as.Date("1949-11-19")))
outl.test <- with(dt.test, !is.na(dateOfBirth) & dateOfBirth %in% c(as.Date("1900-11-19"), as.Date("1949-11-19")))

dt.train[outl.train, ]$dateOfBirth <- NA
dt.test[outl.test, ]$dateOfBirth <- NA
```

Let's take a look again:

```{r}
par(mfrow=c(1, 2))
barplot(table(dt.train$dateOfBirth), main="Histogram of dateOfBirth (Train)")
barplot(table(dt.test$dateOfBirth), main="Histogram of dateOfBirth (Test)")
```

Looks alright.

But... what about the superhumans?

```{r}
head(sort(dt.test$dateOfBirth))
head(sort(dt.train$dateOfBirth))
```

Only three in the train set, so let's set them to NA as well:

```{r}
outl.train <- with(dt.train, !is.na(dateOfBirth) & dateOfBirth == as.Date("1655-04-19"))

dt.train[outl.train, ]$dateOfBirth <- NA
```

Let's compute an age attribute:

```{r}
dt.train$customerAge <- as.integer(year(dt.train$orderDate) - year(dt.train$dateOfBirth))
dt.test$customerAge <- as.integer(year(dt.test$orderDate) - year(dt.test$dateOfBirth))
```

And plot it:
```{r}
par(mfrow=c(1, 2))

hist(dt.train$customerAge, main="Customer Age (Train)")
hist(dt.test$customerAge, main="Customer Age (Test)")
```

There are still some outliers on both ends, so we set them to NA as well:

```{r}
outl.train <- with(dt.train, !is.na(customerAge) & (customerAge > 85 | customerAge < 19))
outl.test <- with(dt.test, !is.na(customerAge) & (customerAge > 85 | customerAge < 19))

dt.train[outl.train, ]$dateOfBirth <- NA
dt.train[outl.train, ]$customerAge <- NA

dt.test[outl.test, ]$dateOfBirth <- NA
dt.test[outl.test, ]$customerAge <- NA
```

Let's do some descriptive statistics:

```{r}
kable(describe2(dt.train$customerAge, dt.test$customerAge))
```

Then we do a Quantile-Quantile plot against the normal distribution:
```{r}
par(mfrow=c(1, 2))

qqnorm(dt.train$customerAge, main="Age per item Normal Q-Q Plot (Train)")
grid()
qqline(dt.train$customerAge, col="red")
qqnorm(dt.test$customerAge, main="Age per item Normal Q-Q Plot (Test)")
grid()
qqline(dt.train$customerAge, col="red")
```

You can clearly see that the age is normally distributed. However, 
due to the slightly positive skew and kurtosis, you can see that the distribution
deviates from the normal distribution in its tails. Do note that this is actually
the customer age per orderItem (per instance), i.e. customers are counted more than
one time if they have ordered more than one item.

What if we count every customer only once?
```{r}
dt.train.customer <- dt.train[!duplicated(dt.train$customerID), ]
dt.test.customer <- dt.test[!duplicated(dt.test$customerID), ]

par(mfrow=c(1, 2))

qqnorm(dt.train.customer$customerAge, main="Age Normal Q-Q Plot (Train)")
grid()
qqline(dt.train.customer$customerAge, col="red")
qqnorm(dt.test.customer$customerAge, main="Age Normal Q-Q Plot (Test)")
grid()
qqline(dt.train.customer$customerAge, col="red")
```
#### Customer Age vs returnShipment

First, let's create a high-dimensional contingency table:

```{r}
x <- structable(returnShipment ~ customerAge, data=dt.train)
x[1:10, ]  # first 10 elements

r <- x[, 2] / (x[, 1] + x[, 2])  # ratio of returned items for each age
plot(rownames(r), r, type="l", main="Ratio of Returned Items vs Age",
     xlab="Age", ylab="Returned Items (Ratio)", col="blue")
grid()
lines(supsmu(as.numeric(rownames(r)), r), col="red")
legend("topright", c("Return Ratio", "Return Ratio (Smoothed (Friedman 1984))"),
       col = c("blue", "red"), lty = 1)
```

### state

```{r}
load(url("http://gadm.org/data/rda/DEU_adm1.RData"))
```

### creationDate

```{r}
tail(sort(table(dt.train$creationDate)))
tail(sort(table(dt.test$creationDate)))
```

The last date appears unusually often. Remove it:

```{r}
outl.train <- with(dt.train, creationDate == as.Date("2011-02-16"))
outl.test <- with(dt.test, creationDate == as.Date("2011-02-16"))

dt.train[outl.train, ]$creationDate <- NA
dt.test[outl.test, ]$creationDate <- NA
```

```{r}
accsum <- cumsum(table(data.table(dt.merged)[,c("creationDate"),
                                            by=list(customerID, creationDate)
                                            ]$creationDate))
plot(as.Date(names(accsum)), accsum, type="l", main="Number of Registered Accounts",
     xlab="Date", ylab="# of Accounts", xaxt="n")
axis(1, as.Date(names(accsum)), format(as.Date(names(accsum)), "%b %y"))
grid()
```

#### Account Age
```{r}
dt.train$accountAge <- as.numeric(dt.train$orderDate - dt.train$creationDate)
dt.test$accountAge <- as.numeric(dt.test$orderDate - dt.test$creationDate)

plot.ddens(dt.train$accountAge, dt.test$accountAge, main="Account Age at Order Date",
           xlab="Age (days)")
```

```{r}
mosaic(returnShipment ~ cut(accountAge, c(0, 50, 200, Inf)), data=dt.train,
       main="Account Age vs returnShipment")
```

Interesting, newer accounts tend to not return items as often as older accounts.

### returnShipment

## holiday skew

Train data date range:

```{r}
range(dt.train$orderDate)
```

Test data date range:

```{r}
range(dt.test$orderDate)
```

Easter Sunday 2012: 2012-04-08
Easter Sunday 2013: 2012-03-31

This means, the train data includes the week before Easter Sunday for both 2012 and 2013 while the test data represents the 30 days after Easter Sunday.

```{r}
train.after.easter <- subset(dt.train, orderDate >= as.Date('2012-04-09') & orderDate < (as.Date('2012-04-09') + days(30)))

nrow(train.after.easter)
nrow(dt.test)

nrow(train.after.easter) / nrow(dt.test)
```
The train data size for the relevant period of the previous year is 71.99% of the test data size.

```{r}
returnRate(train.after.easter)
returnRate(dt.train)
```
The return rate is 48.50% for the after easter period with is similar to the overall return rate.

### afterEaster as Train/Test set (CV)

```{r}
dt.train.ae <- train.after.easter
plot.ddens(dt.train.ae$price, dt.test$price, main="Kernel Density Estimate of Price",
           xlab="Price (EUR)")
```

## Cleaned Data

```{r}
dt.train$customerAge <- NULL
dt.train$deliveryTime <- NULL
dt.train$accountAge <- NULL
write.table(dt.train, file="task/orders_train.clean.txt", sep=";", na="?",
            quote=F, row.names=F)
dt.test$customerAge <- NULL
dt.test$deliveryTime <- NULL
dt.test$accountAge <- NULL
write.table(dt.test, file="task/orders_class.clean.txt", sep=";", na="?",
            quote=F, row.names=F)
```

The cleaned data is [available](http://dwxput6p.0x0b.de/).
Do note that *no* instances have been removed. The
outliers simply had their outlying attribute set to NA/?.

## Missing Value Imputation

```{r}
library(zoo)
dt <- dt.merged[c("orderDate", "creationDate", "customerID")]
dt$firstOrderDate <- as.Date(data.table(dt)[, x := as.integer(min(orderDate)), by=c("customerID")]$x)
dt <- unique(dt[c("firstOrderDate", "creationDate")])
smoothScatter(dt$firstOrderDate, dt$creationDate, xlab="Date of First Order", ylab="Creation Date",
              main="Date of First Order vs Creation Date")
abline(1, 1, col="red")
```

Another obvious idea is to rely on customerID being an incrementing
number, but this isn't always true:

```{r}
dt <- unique(dt.merged[c("creationDate", "customerID")])
smoothScatter(dt$creationDate, dt$customerID, xlab="Creation Date", ylab="Customer ID",
              main="Creation Date vs Customer ID")
```

## SessionInfo

```{r}
sessionInfo()
```

```{r}
date()
```
